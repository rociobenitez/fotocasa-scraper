# Fotocasa Scraper üè†

Este proyecto es un script en Python que utiliza **BeautifulSoup** y **Selenium** para extraer informaci√≥n de propiedades en venta publicadas en [Fotocasa](https://www.fotocasa.es/). El objetivo es obtener datos clave de los anuncios, como t√≠tulo, precio, ubicaci√≥n, superficie, n√∫mero de habitaciones, n√∫mero de ba√±os y enlace al anuncio, y almacenarlos en un archivo CSV.

El c√≥digo actualmente opera en un archivo HTML descargado para pruebas de scraping, y hay una versi√≥n adaptada para combinar Selenium y BeautifulSoup que permite automatizar la navegaci√≥n y capturar contenido din√°mico.

![Web Fotocasa](img/fotocasa-web-macbook.jpg)

## Caracter√≠sticas

- **Automatizaci√≥n de la navegaci√≥n**: Interacci√≥n con la p√°gina mediante Selenium para manejar contenido din√°mico y simulaci√≥n de scroll.
- **Extracci√≥n de datos**: An√°lisis del DOM con BeautifulSoup para capturar:
  - T√≠tulo del anuncio
  - Precio
  - Ubicaci√≥n
  - Superficie
  - Habitaciones y ba√±os
  - Enlace al anuncio
- **Salida estructurada**: Los datos extra√≠dos se guardan en un archivo CSV.

## Limitaciones y Consideraciones

**Bloqueos del sitio:**

- Fotocasa puede bloquear el acceso si detecta un uso automatizado (como scrapers).
- Posibles soluciones:
  - Usar un **User-Agent** realista para simular un navegador.
  - Implementar pausas aleatorias y un scroll m√°s natural para evitar patrones repetitivos.
  - Alternar direcciones IP utilizando una VPN o un servicio de proxies.

**Compatibilidad con versiones de Chrome y ChromeDriver:**

- Es fundamental que las versiones de Google Chrome y ChromeDriver sean compatibles.
- Se recomienda verificar las versiones instaladas ejecutando:
  ```bash
  google-chrome --version
  chromedriver --version
  ```
- Si las versiones no coinciden, descarga la versi√≥n adecuada de ChromeDriver desde [Chrome for Testing](https://googlechromelabs.github.io/chrome-for-testing/).
- Para sistemas macOS, aseg√∫rate de otorgar permisos a `chromedriver` en "Seguridad y Privacidad" si aparece un error de verificaci√≥n de software malicioso.

**Configuraciones adicionales:**

- En el caso de ejecutar el script en GitHub Actions, aseg√∫rate de que las rutas de `chromedriver` y `google-chrome` est√©n configuradas correctamente.

## Requisitos

- **Python** 3.10 o superior
- **Google Chrome:** Aseg√∫rate de tener instalada la versi√≥n m√°s reciente de Google Chrome.
- **ChromeDriver:** Debes descargar e instalar la versi√≥n correcta de ChromeDriver que coincida con tu versi√≥n de Chrome.
  - Para sistemas Unix/macOS, mueve el binario a `/usr/local/bin`:
  ```bash
  sudo mv chromedriver /usr/local/bin/chromedriver
  ```
  - Verifica que ChromeDriver est√© instalado correctamente:
    ```bash
    chromedriver --version
    ```
- **Librer√≠as necesarias**:
  ```bash
  pip install -r requirements.txt
  ```

## Estructura del Proyecto

```plaintext
fotocasa-scraper/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ main.yml         # Configuraci√≥n para GitHub Actions
‚îú‚îÄ‚îÄ img                      # Recursos de im√°genes
‚îú‚îÄ‚îÄ main.py                  # Script principal (Selenium y BeautifulSoup)
‚îú‚îÄ‚îÄ requirements.txt         # Dependencias del proyecto
‚îú‚îÄ‚îÄ data
|   ‚îî‚îÄ‚îÄ pisos_fotocasa.csv   # CSV generado por el script
‚îî‚îÄ‚îÄ README.md                # Documentaci√≥n del proyecto
```

## Ejecuci√≥n del script en local

1. **Activa el entorno virtual:**

```bash
source .venv/bin/activate
```

2. **Configuraci√≥n de dependencias:**

```bash
pip install -r requirements.txt
```

3. **Verifica que chromedriver est√° configurado:**

```bash
chromedriver --version
```

4. **Ejecuta el script:**

```bash
python main.py
```

El script:

- Acepta cookies autom√°ticamente.
- Realiza un scroll simulado para cargar todos los anuncios.
- Navega por las p√°ginas hasta que no haya m√°s resultados.
- Guarda los datos extra√≠dos en un archivo CSV (`data/pisos_fotocasa.csv`).

## Automatizaci√≥n con GitHub Actions

El proyecto est√° configurado para ejecutarse autom√°ticamente en GitHub Actions, lo que permite realizar scraping sin necesidad de ejecutarlo localmente. Esto es especialmente √∫til para programar tareas autom√°ticas o recopilar datos de manera regular.

### Configuraci√≥n del Workflow

El archivo de configuraci√≥n del workflow se encuentra en `.github/workflows/fotocasa-scraper.yml`. El flujo incluye los siguientes pasos:

1. **Configurar el entorno:**

   - Instala Python y las dependencias necesarias.
   - Configura Google Chrome y ChromeDriver.

2. **Ejecutar el script:**

   - El script se ejecuta autom√°ticamente en el entorno configurado y genera el archivo `data/pisos_fotocasa.csv`.

3. **Programaci√≥n autom√°tica:**
   - El workflow est√° configurado para ejecutarse autom√°ticamente cada lunes a las 9:00 AM (UTC) mediante el siguiente cron:
     ```yaml
     on:
       schedule:
         - cron: "0 9 * * 1"
     ```

### C√≥mo Personalizar el Workflow

- Si deseas cambiar la periodicidad del scraping, modifica el cron en `.github/workflows/fotocasa-scraper.yml`.
- Puedes a√±adir notificaciones o tareas adicionales, como subir los resultados a un repositorio o enviarlos por correo.

## Enlaces de Referencia

- üîó [Documentaci√≥n de Selenium](https://www.selenium.dev/documentation/)
- üîó [Documentaci√≥n de BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- üîó [Descargar ChromeDriver](https://googlechromelabs.github.io/chrome-for-testing/)

> [!NOTE]
> Este proyecto es de uso personal y educativo. Fotocasa puede bloquear el acceso a su sitio si detecta patrones automatizados. Aseg√∫rate de respetar los t√©rminos de uso del sitio.
